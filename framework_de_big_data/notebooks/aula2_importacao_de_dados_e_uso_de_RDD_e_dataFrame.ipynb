{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importação de dados e Uso de RDD e DataFrame"
      ],
      "metadata": {
        "id": "gjgDBFo78tiA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuração de biblioteca do PysPark"
      ],
      "metadata": {
        "id": "YmUC6z518dU6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6ECJQyQ7_in",
        "outputId": "4512a0fc-9bc9-42c1-bf95-ac7a8a9d5b1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=804ce3a72e2b63c0e1cebc601962b1e6d4a70452694e6c8d063036459ba9ba6c\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criando a sessão do SparkContext e SparkSession"
      ],
      "metadata": {
        "id": "mJw7rkm58kRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "jUF6ZudV8jbe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = SparkContext.getOrCreate()"
      ],
      "metadata": {
        "id": "EvoBGdFF8zkf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName('PySpark DataFrame From RDD').getOrCreate()"
      ],
      "metadata": {
        "id": "JYDO0kWt82Lb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create PySpark Dataframe from an Existing RDD"
      ],
      "metadata": {
        "id": "IChOb7ht85KC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize([('C',85,76,87,91), ('B',85,76,87,91), (\"A\", 85,78,96,92), (\"A\", 92,76,89,96)], 4)"
      ],
      "metadata": {
        "id": "SGH5w8Ls84OG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(rdd))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PW-VnZ7M8--C",
        "outputId": "df5f54b2-9a59-495a-bdad-a2cd831018e6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pyspark.rdd.RDD'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub = ['id_person','value_1','value_2','value_3','value_4']"
      ],
      "metadata": {
        "id": "TiRjK8sk9Abc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "marks_df = spark.createDataFrame(rdd, schema=sub)"
      ],
      "metadata": {
        "id": "Sg7-vb829Bvu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(marks_df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpskY2Nc9C87",
        "outputId": "5cd16d3f-c9d0-4e6e-e8a7-24e4137e6f20"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pyspark.sql.dataframe.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "marks_df.printSchema()"
      ],
      "metadata": {
        "id": "q1iaiiiJ9FQy",
        "outputId": "14efe16d-8fdf-4818-802b-d7850509c5bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id_person: string (nullable = true)\n",
            " |-- value_1: long (nullable = true)\n",
            " |-- value_2: long (nullable = true)\n",
            " |-- value_3: long (nullable = true)\n",
            " |-- value_4: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "marks_df.show()"
      ],
      "metadata": {
        "id": "b_IcOOe59HUh",
        "outputId": "0d019d00-96ae-44b8-ecb7-727d7648cc76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------+-------+-------+-------+\n",
            "|id_person|value_1|value_2|value_3|value_4|\n",
            "+---------+-------+-------+-------+-------+\n",
            "|        C|     85|     76|     87|     91|\n",
            "|        B|     85|     76|     87|     91|\n",
            "|        A|     85|     78|     96|     92|\n",
            "|        A|     92|     76|     89|     96|\n",
            "+---------+-------+-------+-------+-------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}